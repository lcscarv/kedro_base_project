{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Project Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook has been designed to assist Indicium's data scientists and machine learning practitioners in efficiently prototyping, developing, and deploying ML models through Kedro. A good practice is to develop, document and test Kedro nodes in this notebook, and further collect those nodes and define their respective pipelines. \n",
    "\n",
    "Although not all steps in a machine learning project can be considered as Kedro nodes, those identified as [Node] are likely to become Kedro nodes, while those identified as [Pipeline] are likely to become a Kedro pipeline. It is important to note that many of these steps, and potentially others, must be executed and thoroughly documented to ensure project reproducibility, facilitate future iterations and review.\n",
    "\n",
    "In this section, **state the project's context, goals and success metrics.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Data Glossary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to maintain good documentation practices, it is highly recommended to create a glossary for terms that will be used throughout the report. It helps ensure that everyone who is working with the data has a shared understanding of the terms and concepts being used, and that there is consistency in how the data is analyzed and interpreted. Therefore providing a central reference point for defining key terms, specifying units of measure, and explaining any assumptions or limitations being applied."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* EDA: Exploratory Data Analysis\n",
    "* Base projects: Indicium core product with templates and example implementations of models and mlops best practices. [Make sure to check out the repo](https://bitbucket.org/indiciumtech/workspace/projects/MLOPS).\n",
    "* [...]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Import Libraries and Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To keep things organized, make sure to add all your library imports in this section. This will be helpful when defining the project's requirements. \n",
    "\n",
    "ðŸ’¡ As a standard at Indicium, there is a [recommended code style](https://bitbucket.org/indiciumtech/indicium-code-style/src/master/data_science/) for Data Science projects. This will help you structure your code and ease review "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explore the data used in the project and provide a detailed analysis of its structure, size, and quality. Identify any missing data, outliers, or anomalies that may impact the results of the project. As the data may come from Analytics Enginering team, most of these steps may have been already taken - in that case, make sure to add links to the table "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Important topics that can be addressed on EDA:\n",
    "\n",
    "- Analyzing Data Distribution: Examining the spread and shape of the data can provide insights into the underlying population and help to identify any potential issues or biases in the data.\n",
    "\n",
    "- Summarizing Data Statistics: Calculating various statistics for different variables, such as mean, median, and standard deviation, can help to summarize the characteristics of the data and identify any patterns or anomalies.\n",
    "\n",
    "- Missing Values: Identifying rows with missing values is important to ensure that the data is complete and can be used for analysis.\n",
    "\n",
    "- Outlier Detection: Detecting outliers is crucial to ensure that they are not skewing the analysis or causing inaccuracies.\n",
    "\n",
    "- Categorical Variables: Examining the number of distinct values for categorical variables can provide insights into the distribution of the data and identify any potential issues or biases.\n",
    "\n",
    "- Comparison with Literature: Comparing the data with other models in literature can help to identify missing information, inconsistencies, and biases in the data, and improve the quality of the analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __[Pipeline]__ 2.1 Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform any necessary data preprocessing, cleaning, and transformations to prepare the data for further steps. Document the steps taken to clean and transform the data. In this section, most of the processing nodes will be created, therefore, the following sub sections may provide a common data science pipeline.\n",
    "\n",
    "1. **[Node]** Feature Selection/Creation: techniques such as correlation analysis, feature importance ranking, or dimensionality reduction could be used to identify the most relevant features, or combine them using other techiniques such as PCA analysis.\n",
    "\n",
    "2. __[Node]__ Feature Encoding: transform categorical features into numeric by using one-hot encoding, ordinal encoding, or target encoding.\n",
    "\n",
    "3. __[Node]__ Feature Scaling: reduce discrepance between features by applying techniques such as min-max scaling, z-score scaling, and robust scaling. \n",
    "\n",
    "4. **[Node]** Data Split: the data frame is split into training and validation datasets.\n",
    "\n",
    "ðŸ’¡ The base projects initiative has created few different implementations for machine learning problem types such as classification, regression and hierarchical time series. Make sure to explore the [kedro repositories]() and reuse any nodes that can useful for your report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **[Pipeline]** 2.2 Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Develop and document the modeling approach to the project. This stage will include at least:\n",
    "\n",
    "1. Model selection: select appropriate machine learning algorithms well-suited to the project by evaluating its performance. More than one algorithm may be appropriate, in which case a model ensemble strategy needs to be defined. \n",
    "\n",
    "2. **[Node]** Model training and tuning: Train the machine learning model on training data, and by cross-validation tune  hyperparameters to optimize its performance.\n",
    "\n",
    "3. **[Node]** Model evaluation: It's important to evaluate the performance of the different models that are being considered. This involves selecting specific metrics that are appropriate for each model and then evaluating the model's performance based on those metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **[Pipeline]** 2.3 Inferencing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The inferencing pipeline acts as the serving component: to serve a model is to expose it to the real world and generate predictions on live data. At this stage of the exploration, it's important to define some production requirements such as expected performance and how it will be measured, latency,  fault-tolerance, etc.\n",
    "\n",
    "1. **[Node]** Model serving: use the model selected on data science pipeline to make prediction on live data.\n",
    "2. **[Node]** Registry: register the predicted values and other information (timestamp, model version, etc.) that will be needed to monitor the models' performances over time "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Useful Links and References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add links and references used in the development of this project."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
